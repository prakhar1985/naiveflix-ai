{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ Improved MPNet Movie Genre Classification\n",
    "## Production-Ready Implementation with Security, Modularity & Performance\n",
    "\n",
    "### Key Improvements:\n",
    "- ‚úÖ **Security**: Replaced `eval()` with `json.loads()`\n",
    "- ‚úÖ **Modularity**: Separated concerns into classes\n",
    "- ‚úÖ **Error Handling**: Comprehensive validation and error handling\n",
    "- ‚úÖ **Model Persistence**: Save/load trained models\n",
    "- ‚úÖ **Configuration**: YAML-based configuration management\n",
    "- ‚úÖ **Cross-Validation**: Robust model evaluation\n",
    "- ‚úÖ **Logging**: Proper logging instead of print statements\n",
    "- ‚úÖ **Performance**: Optimized embeddings and caching\n",
    "\n",
    "**Accuracy Target**: 55%+ (vs original 54.3%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Installation & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package with verbose output\"\"\"\n",
    "    try:\n",
    "        print(f\"   Running: pip install {package}\")\n",
    "        result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", package], \n",
    "                               check=True, text=True)\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"   ‚ùå Installation failed: {e}\")\n",
    "        return False\n",
    "\n",
    "required_packages = [\n",
    "    'sentence-transformers>=2.2.0',\n",
    "    'scikit-learn>=1.3.0', \n",
    "    'xgboost>=1.7.0',\n",
    "    'pandas>=2.0.0',\n",
    "    'numpy>=1.24.0',\n",
    "    'matplotlib>=3.7.0',\n",
    "    'seaborn>=0.12.0',\n",
    "    'tqdm>=4.65.0',\n",
    "    'pyyaml>=6.0',\n",
    "    'joblib>=1.3.0',\n",
    "    'flask>=2.3.0',\n",
    "    'skl2onnx==1.15.0',\n",
    "    'onnx==1.14.1',\n",
    "    'onnxruntime==1.15.1'\n",
    "]\n",
    "\n",
    "missing_packages = []\n",
    "for package in required_packages:\n",
    "    package_name = package.split('>=')[0].split('==')[0]\n",
    "    try:\n",
    "        # Handle special import names\n",
    "        if package_name == 'sentence-transformers':\n",
    "            import sentence_transformers\n",
    "        elif package_name == 'scikit-learn':\n",
    "            import sklearn\n",
    "        elif package_name == 'pyyaml':\n",
    "            import yaml\n",
    "        else:\n",
    "            __import__(package_name.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"üì¶ Installing {len(missing_packages)} missing packages...\")\n",
    "    for package in missing_packages:\n",
    "        if not install_package(package):\n",
    "            print(f\"‚ùå Failed to install {package}\")\n",
    "    print(\"‚úÖ Installation complete!\")\n",
    "else:\n",
    "    print(\"‚úÖ All packages already installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Configuration Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "import os\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    name: str\n",
    "    embedding_model: str\n",
    "    embedding_dim: int\n",
    "    max_seq_length: int\n",
    "    batch_size: int\n",
    "    normalize_embeddings: bool\n",
    "\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "    dataset_path: str\n",
    "    min_plot_length: int\n",
    "    max_genres: int\n",
    "    test_size: float\n",
    "    random_state: int\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    cv_folds: int\n",
    "    n_jobs: int\n",
    "    scoring: str\n",
    "    classifiers: Dict\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    model: ModelConfig\n",
    "    data: DataConfig\n",
    "    training: TrainingConfig\n",
    "    output_dir: str\n",
    "    logging_level: str\n",
    "\n",
    "# Default configuration\n",
    "default_config = {\n",
    "    'model': {\n",
    "        'name': 'mpnet-movie-classifier',\n",
    "        'embedding_model': 'all-mpnet-base-v2',\n",
    "        'embedding_dim': 768,\n",
    "        'max_seq_length': 512,\n",
    "        'batch_size': 32,\n",
    "        'normalize_embeddings': True\n",
    "    },\n",
    "    'data': {\n",
    "        'dataset_path': 'tmdb_5000_movies.csv',\n",
    "        'min_plot_length': 50,\n",
    "        'max_genres': 8,\n",
    "        'test_size': 0.2,\n",
    "        'random_state': 42\n",
    "    },\n",
    "    'training': {\n",
    "        'cv_folds': 5,\n",
    "        'n_jobs': -1,\n",
    "        'scoring': 'accuracy',\n",
    "        'classifiers': {\n",
    "            'RandomForest': {\n",
    "                'n_estimators': [200],\n",
    "                'max_depth': [20],\n",
    "                'min_samples_split': [2]\n",
    "            },\n",
    "            'LogisticRegression': {\n",
    "                'C': [1.0],\n",
    "                'max_iter': [2000]\n",
    "            },\n",
    "            'XGBoost': {\n",
    "                'n_estimators': [100],\n",
    "                'max_depth': [6],\n",
    "                'learning_rate': [0.1]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'output_dir': 'models',\n",
    "    'logging_level': 'INFO'\n",
    "}\n",
    "\n",
    "def load_config(config_path: Optional[str] = None) -> Config:\n",
    "    \"\"\"Load configuration from YAML file or use defaults\"\"\"\n",
    "    if config_path and os.path.exists(config_path):\n",
    "        with open(config_path, 'r') as f:\n",
    "            config_dict = yaml.safe_load(f)\n",
    "    else:\n",
    "        config_dict = default_config\n",
    "    \n",
    "    return Config(\n",
    "        model=ModelConfig(**config_dict['model']),\n",
    "        data=DataConfig(**config_dict['data']),\n",
    "        training=TrainingConfig(**config_dict['training']),\n",
    "        output_dir=config_dict['output_dir'],\n",
    "        logging_level=config_dict['logging_level']\n",
    "    )\n",
    "\n",
    "config = load_config()\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"üìä Model: {config.model.embedding_model}\")\n",
    "print(f\"üìÅ Dataset: {config.data.dataset_path}\")\n",
    "print(f\"üéØ Max genres: {config.data.max_genres}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=getattr(logging, config.logging_level),\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler(f'movie_classifier_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"üé¨ Starting MPNet Movie Genre Classification\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(config.output_dir, exist_ok=True)\n",
    "logger.info(f\"üìÅ Output directory: {config.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import Tuple, Union, List, Dict, Any\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML imports\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, \n",
    "    precision_recall_fscore_support, roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    HAS_XGBOOST = True\n",
    "    logger.info(\"‚úÖ XGBoost available\")\n",
    "except ImportError:\n",
    "    HAS_XGBOOST = False\n",
    "    logger.warning(\"‚ö†Ô∏è XGBoost not available\")\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"üîß Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"Secure and robust data processing pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, config: DataConfig):\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def load_dataset(self) -> pd.DataFrame:\n",
    "        \"\"\"Load and validate dataset\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(self.config.dataset_path)\n",
    "            self.logger.info(f\"üìÇ Dataset loaded: {df.shape}\")\n",
    "            return df\n",
    "        except FileNotFoundError:\n",
    "            self.logger.error(f\"‚ùå Dataset not found: {self.config.dataset_path}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Error loading dataset: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def extract_primary_genre(self, genres_str: str) -> Optional[str]:\n",
    "        \"\"\"Safely extract primary genre using json.loads instead of eval\"\"\"\n",
    "        if pd.isna(genres_str) or not genres_str.strip():\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Handle string format issues\n",
    "            genres_str = genres_str.replace(\"'\", '\"')  # Convert single quotes to double quotes\n",
    "            genres_list = json.loads(genres_str)\n",
    "            \n",
    "            if isinstance(genres_list, list) and len(genres_list) > 0:\n",
    "                if isinstance(genres_list[0], dict) and 'name' in genres_list[0]:\n",
    "                    return genres_list[0]['name']\n",
    "        except (json.JSONDecodeError, KeyError, IndexError, TypeError) as e:\n",
    "            self.logger.debug(f\"Failed to parse genre: {genres_str[:50]}... Error: {e}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def validate_text(self, text: str) -> bool:\n",
    "        \"\"\"Validate text quality\"\"\"\n",
    "        if pd.isna(text) or not isinstance(text, str):\n",
    "            return False\n",
    "        \n",
    "        # Check minimum length\n",
    "        if len(text.strip()) < self.config.min_plot_length:\n",
    "            return False\n",
    "        \n",
    "        # Check for meaningful content (not just special characters)\n",
    "        if not any(c.isalnum() for c in text):\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def process_dataset(self, df: pd.DataFrame) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"Process dataset with comprehensive validation\"\"\"\n",
    "        self.logger.info(\"üîß Processing dataset...\")\n",
    "        \n",
    "        # Check required columns\n",
    "        required_cols = ['overview', 'genres']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Clean data\n",
    "        df_clean = df.dropna(subset=['overview', 'genres']).copy()\n",
    "        self.logger.info(f\"üìä After removing NaN: {len(df_clean)} movies\")\n",
    "        \n",
    "        # Extract genres safely\n",
    "        df_clean['primary_genre'] = df_clean['genres'].apply(self.extract_primary_genre)\n",
    "        df_clean = df_clean.dropna(subset=['primary_genre'])\n",
    "        self.logger.info(f\"üìä After genre extraction: {len(df_clean)} movies\")\n",
    "        \n",
    "        # Validate text quality\n",
    "        valid_mask = df_clean['overview'].apply(self.validate_text)\n",
    "        df_clean = df_clean[valid_mask]\n",
    "        self.logger.info(f\"üìä After text validation: {len(df_clean)} movies\")\n",
    "        \n",
    "        if len(df_clean) == 0:\n",
    "            raise ValueError(\"No valid data remaining after processing\")\n",
    "        \n",
    "        # Select top genres\n",
    "        genre_counts = df_clean['primary_genre'].value_counts()\n",
    "        self.logger.info(f\"üé≠ Genre distribution:\\n{genre_counts.head(10)}\")\n",
    "        \n",
    "        top_genres = genre_counts.head(self.config.max_genres).index.tolist()\n",
    "        df_final = df_clean[df_clean['primary_genre'].isin(top_genres)].copy()\n",
    "        \n",
    "        self.logger.info(f\"üéØ Final dataset: {len(df_final)} movies, {len(top_genres)} genres\")\n",
    "        \n",
    "        # Prepare output\n",
    "        texts = df_final['overview'].tolist()\n",
    "        labels = df_final['primary_genre'].tolist()\n",
    "        \n",
    "        # Log statistics\n",
    "        avg_length = np.mean([len(text.split()) for text in texts])\n",
    "        self.logger.info(f\"üìä Average plot length: {avg_length:.1f} words\")\n",
    "        \n",
    "        return texts, labels\n",
    "\n",
    "# Initialize processor\n",
    "processor = DataProcessor(config.data)\n",
    "print(\"‚úÖ Data processor initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Embedding Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingGenerator:\n",
    "    \"\"\"Optimized embedding generation with caching\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.model = None\n",
    "        self._cache = {}\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load embedding model\"\"\"\n",
    "        self.logger.info(f\"üß† Loading {self.config.embedding_model}...\")\n",
    "        \n",
    "        try:\n",
    "            self.model = SentenceTransformer(self.config.embedding_model)\n",
    "            \n",
    "            # Move to GPU if available\n",
    "            if device.type == 'cuda':\n",
    "                self.model = self.model.to(device)\n",
    "                self.logger.info(\"üöÄ Model moved to GPU\")\n",
    "            \n",
    "            # Log model info\n",
    "            self.logger.info(f\"‚úÖ Model loaded: {self.config.embedding_model}\")\n",
    "            self.logger.info(f\"üìê Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "            self.logger.info(f\"üìè Max sequence length: {self.model.max_seq_length}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Failed to load model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def generate_embeddings(self, texts: List[str], use_cache: bool = True) -> np.ndarray:\n",
    "        \"\"\"Generate embeddings with progress tracking and caching\"\"\"\n",
    "        if self.model is None:\n",
    "            self.load_model()\n",
    "        \n",
    "        cache_key = hash(tuple(texts)) if use_cache else None\n",
    "        \n",
    "        if use_cache and cache_key in self._cache:\n",
    "            self.logger.info(\"üìã Using cached embeddings\")\n",
    "            return self._cache[cache_key]\n",
    "        \n",
    "        self.logger.info(f\"üîÑ Generating embeddings for {len(texts)} texts...\")\n",
    "        self.logger.info(\"‚è∞ This might take a few minutes, but it's worth the wait...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            embeddings = self.model.encode(\n",
    "                texts,\n",
    "                batch_size=self.config.batch_size,\n",
    "                show_progress_bar=True,\n",
    "                device=device.type,\n",
    "                normalize_embeddings=self.config.normalize_embeddings,\n",
    "                convert_to_numpy=True\n",
    "            )\n",
    "            \n",
    "            duration = time.time() - start_time\n",
    "            self.logger.info(f\"‚úÖ Embeddings generated in {duration:.2f}s\")\n",
    "            self.logger.info(f\"üìä Shape: {embeddings.shape}\")\n",
    "            self.logger.info(f\"üíæ Memory: {embeddings.nbytes / 1e6:.1f}MB\")\n",
    "            \n",
    "            if use_cache:\n",
    "                self._cache[cache_key] = embeddings\n",
    "            \n",
    "            return embeddings\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Failed to generate embeddings: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def clear_cache(self):\n",
    "        \"\"\"Clear embedding cache\"\"\"\n",
    "        self._cache.clear()\n",
    "        self.logger.info(\"üóëÔ∏è Cache cleared\")\n",
    "\n",
    "# Initialize embedding generator\n",
    "embedding_gen = EmbeddingGenerator(config.model)\n",
    "print(\"‚úÖ Embedding generator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Enhanced Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"Advanced model training with cross-validation and hyperparameter tuning\"\"\"\n",
    "    \n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.best_model = None\n",
    "        self.best_params = None\n",
    "        self.results = {}\n",
    "    \n",
    "    def prepare_data(self, embeddings: np.ndarray, labels: List[str]) -> Tuple:\n",
    "        \"\"\"Prepare data for training with class balancing\"\"\"\n",
    "        self.logger.info(\"üìö Preparing training data...\")\n",
    "        \n",
    "        # Encode labels\n",
    "        encoded_labels = self.label_encoder.fit_transform(labels)\n",
    "        \n",
    "        # Log label mapping\n",
    "        self.logger.info(\"üè∑Ô∏è Label mapping:\")\n",
    "        for i, genre in enumerate(self.label_encoder.classes_):\n",
    "            count = (encoded_labels == i).sum()\n",
    "            self.logger.info(f\"  ‚Ä¢ {genre}: {count} movies (label {i})\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            embeddings, \n",
    "            encoded_labels, \n",
    "            test_size=config.data.test_size, \n",
    "            random_state=config.data.random_state,\n",
    "            stratify=encoded_labels\n",
    "        )\n",
    "        \n",
    "        self.logger.info(f\"üìä Training: {len(X_train)}, Testing: {len(X_test)}\")\n",
    "        \n",
    "        # Compute class weights for balanced training\n",
    "        class_weights = compute_class_weight(\n",
    "            'balanced', \n",
    "            classes=np.unique(y_train), \n",
    "            y=y_train\n",
    "        )\n",
    "        self.class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def get_classifiers(self) -> Dict:\n",
    "        \"\"\"Get classifiers with hyperparameter grids\"\"\"\n",
    "        classifiers = {\n",
    "            'RandomForest': (\n",
    "                RandomForestClassifier(\n",
    "                    random_state=config.data.random_state,\n",
    "                    n_jobs=self.config.n_jobs,\n",
    "                    class_weight='balanced'\n",
    "                ),\n",
    "                self.config.classifiers.get('RandomForest', {})\n",
    "            ),\n",
    "            'LogisticRegression': (\n",
    "                LogisticRegression(\n",
    "                    random_state=config.data.random_state,\n",
    "                    class_weight='balanced',\n",
    "                    n_jobs=self.config.n_jobs\n",
    "                ),\n",
    "                self.config.classifiers.get('LogisticRegression', {})\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        if HAS_XGBOOST:\n",
    "            classifiers['XGBoost'] = (\n",
    "                xgb.XGBClassifier(\n",
    "                    random_state=config.data.random_state,\n",
    "                    eval_metric='mlogloss',\n",
    "                    n_jobs=self.config.n_jobs\n",
    "                ),\n",
    "                self.config.classifiers.get('XGBoost', {})\n",
    "            )\n",
    "        \n",
    "        return classifiers\n",
    "    \n",
    "    def train_with_cv(self, X_train: np.ndarray, y_train: np.ndarray) -> Dict:\n",
    "        \"\"\"Train models with cross-validation and hyperparameter tuning\"\"\"\n",
    "        self.logger.info(\"üèãÔ∏è Training models with cross-validation...\")\n",
    "        self.logger.info(\"‚è∞ Note: This training step will take 1-2 minutes - optimized for speed! ‚òï\")\n",
    "        \n",
    "        classifiers = self.get_classifiers()\n",
    "        cv = StratifiedKFold(n_splits=self.config.cv_folds, shuffle=True, \n",
    "                           random_state=config.data.random_state)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for name, (classifier, param_grid) in classifiers.items():\n",
    "            self.logger.info(f\"üîÑ Training {name}...\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                if param_grid:  # Hyperparameter tuning\n",
    "                    grid_search = GridSearchCV(\n",
    "                        classifier,\n",
    "                        param_grid,\n",
    "                        cv=cv,\n",
    "                        scoring=self.config.scoring,\n",
    "                        n_jobs=self.config.n_jobs,\n",
    "                        verbose=0\n",
    "                    )\n",
    "                    grid_search.fit(X_train, y_train)\n",
    "                    \n",
    "                    best_estimator = grid_search.best_estimator_\n",
    "                    best_score = grid_search.best_score_\n",
    "                    best_params = grid_search.best_params_\n",
    "                    \n",
    "                else:  # Default parameters\n",
    "                    scores = cross_val_score(classifier, X_train, y_train, \n",
    "                                           cv=cv, scoring=self.config.scoring)\n",
    "                    classifier.fit(X_train, y_train)\n",
    "                    \n",
    "                    best_estimator = classifier\n",
    "                    best_score = scores.mean()\n",
    "                    best_params = {}\n",
    "                \n",
    "                duration = time.time() - start_time\n",
    "                \n",
    "                results[name] = {\n",
    "                    'model': best_estimator,\n",
    "                    'cv_score': best_score,\n",
    "                    'cv_std': 0,  # Will be calculated properly if needed\n",
    "                    'best_params': best_params,\n",
    "                    'training_time': duration\n",
    "                }\n",
    "                \n",
    "                self.logger.info(f\"‚úÖ {name}: CV Score = {best_score:.3f} ({duration:.1f}s)\")\n",
    "                if best_params:\n",
    "                    self.logger.info(f\"   Best params: {best_params}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"‚ùå Failed to train {name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Find best model\n",
    "        if results:\n",
    "            best_name = max(results, key=lambda x: results[x]['cv_score'])\n",
    "            self.best_model = results[best_name]['model']\n",
    "            self.best_params = results[best_name]['best_params']\n",
    "            \n",
    "            self.logger.info(f\"üèÜ Best model: {best_name} (CV: {results[best_name]['cv_score']:.3f})\")\n",
    "        \n",
    "        self.results = results\n",
    "        return results\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = ModelTrainer(config.training)\n",
    "print(\"‚úÖ Model trainer initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    \"\"\"Handle model saving and loading with metadata\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: str):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def save_model(self, trainer: ModelTrainer, embedding_gen: EmbeddingGenerator, \n",
    "                  config: Config, metrics: Dict) -> str:\n",
    "        \"\"\"Save complete model pipeline with metadata\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        model_dir = self.output_dir / f\"model_{timestamp}\"\n",
    "        model_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            # Save best model\n",
    "            joblib.dump(trainer.best_model, model_dir / \"classifier.pkl\")\n",
    "            \n",
    "            # Save label encoder\n",
    "            joblib.dump(trainer.label_encoder, model_dir / \"label_encoder.pkl\")\n",
    "            \n",
    "            # Save metadata\n",
    "            metadata = {\n",
    "                'timestamp': timestamp,\n",
    "                'config': {\n",
    "                    'embedding_model': config.model.embedding_model,\n",
    "                    'max_genres': config.data.max_genres,\n",
    "                    'test_size': config.data.test_size\n",
    "                },\n",
    "                'best_params': trainer.best_params,\n",
    "                'metrics': metrics,\n",
    "                'label_classes': trainer.label_encoder.classes_.tolist()\n",
    "            }\n",
    "            \n",
    "            with open(model_dir / \"metadata.json\", 'w') as f:\n",
    "                json.dump(metadata, f, indent=2, default=str)\n",
    "            \n",
    "            # Save config\n",
    "            with open(model_dir / \"config.yaml\", 'w') as f:\n",
    "                yaml.dump(default_config, f, default_flow_style=False)\n",
    "            \n",
    "            self.logger.info(f\"üíæ Model saved to {model_dir}\")\n",
    "            return str(model_dir)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Failed to save model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def load_model(self, model_path: str) -> Tuple:\n",
    "        \"\"\"Load complete model pipeline\"\"\"\n",
    "        model_dir = Path(model_path)\n",
    "        \n",
    "        try:\n",
    "            # Load model components\n",
    "            classifier = joblib.load(model_dir / \"classifier.pkl\")\n",
    "            label_encoder = joblib.load(model_dir / \"label_encoder.pkl\")\n",
    "            \n",
    "            # Load metadata\n",
    "            with open(model_dir / \"metadata.json\", 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "            \n",
    "            self.logger.info(f\"üìÇ Model loaded from {model_dir}\")\n",
    "            return classifier, label_encoder, metadata\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Failed to load model: {e}\")\n",
    "            raise\n",
    "\n",
    "# Initialize model manager\n",
    "model_manager = ModelManager(config.output_dir)\n",
    "print(\"‚úÖ Model manager initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Main Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "logger.info(\"üìä Starting data processing pipeline...\")\n",
    "df = processor.load_dataset()\n",
    "texts, labels = processor.process_dataset(df)\n",
    "\n",
    "# Generate embeddings\n",
    "logger.info(\"üß† Generating embeddings...\")\n",
    "embeddings = embedding_gen.generate_embeddings(texts)\n",
    "\n",
    "# Prepare training data\n",
    "X_train, X_test, y_train, y_test = trainer.prepare_data(embeddings, labels)\n",
    "\n",
    "# Train models\n",
    "logger.info(\"üèãÔ∏è Training models...\")\n",
    "training_results = trainer.train_with_cv(X_train, y_train)\n",
    "\n",
    "print(\"\\nüéâ Training pipeline completed!\")\n",
    "print(f\"üìä Results summary:\")\n",
    "for name, result in training_results.items():\n",
    "    print(f\"  ‚Ä¢ {name}: {result['cv_score']:.3f} ({result['training_time']:.1f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Enhanced Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    \n",
    "    def __init__(self, trainer: ModelTrainer):\n",
    "        self.trainer = trainer\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def evaluate_model(self, X_test: np.ndarray, y_test: np.ndarray) -> Dict:\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        self.logger.info(\"üìä Evaluating best model...\")\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = self.trainer.best_model.predict(X_test)\n",
    "        y_pred_proba = self.trainer.best_model.predict_proba(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        }\n",
    "        \n",
    "        # Classification report\n",
    "        target_names = self.trainer.label_encoder.classes_\n",
    "        class_report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "        \n",
    "        self.logger.info(f\"üéØ Test Accuracy: {accuracy:.3f} ({accuracy*100:.1f}%)\")\n",
    "        self.logger.info(f\"üìä Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "        \n",
    "        return {\n",
    "            'metrics': metrics,\n",
    "            'classification_report': class_report,\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_pred_proba\n",
    "        }\n",
    "    \n",
    "    def plot_confusion_matrix(self, y_test: np.ndarray, y_pred: np.ndarray, save_path: str = None):\n",
    "        \"\"\"Plot enhanced confusion matrix\"\"\"\n",
    "        target_names = self.trainer.label_encoder.classes_\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=target_names, yticklabels=target_names,\n",
    "                   cbar_kws={'label': 'Count'})\n",
    "        \n",
    "        plt.title(f'Confusion Matrix - MPNet Movie Genre Classifier\\nTest Accuracy: {accuracy_score(y_test, y_pred):.1%}', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Predicted Genre', fontsize=12)\n",
    "        plt.ylabel('True Genre', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            self.logger.info(f\"üìä Confusion matrix saved to {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def plot_per_genre_performance(self, class_report: Dict, save_path: str = None):\n",
    "        \"\"\"Plot per-genre performance metrics\"\"\"\n",
    "        genres = [k for k in class_report.keys() if k not in ['accuracy', 'macro avg', 'weighted avg']]\n",
    "        \n",
    "        metrics_data = {\n",
    "            'Genre': genres,\n",
    "            'Precision': [class_report[g]['precision'] for g in genres],\n",
    "            'Recall': [class_report[g]['recall'] for g in genres],\n",
    "            'F1-Score': [class_report[g]['f1-score'] for g in genres],\n",
    "            'Support': [class_report[g]['support'] for g in genres]\n",
    "        }\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Precision\n",
    "        axes[0,0].bar(metrics_data['Genre'], metrics_data['Precision'], color='skyblue')\n",
    "        axes[0,0].set_title('Precision by Genre')\n",
    "        axes[0,0].set_ylim(0, 1)\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Recall\n",
    "        axes[0,1].bar(metrics_data['Genre'], metrics_data['Recall'], color='lightcoral')\n",
    "        axes[0,1].set_title('Recall by Genre')\n",
    "        axes[0,1].set_ylim(0, 1)\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # F1-Score\n",
    "        axes[1,0].bar(metrics_data['Genre'], metrics_data['F1-Score'], color='lightgreen')\n",
    "        axes[1,0].set_title('F1-Score by Genre')\n",
    "        axes[1,0].set_ylim(0, 1)\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Support\n",
    "        axes[1,1].bar(metrics_data['Genre'], metrics_data['Support'], color='gold')\n",
    "        axes[1,1].set_title('Support (Number of Samples) by Genre')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            self.logger.info(f\"üìä Performance plot saved to {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = ModelEvaluator(trainer)\n",
    "evaluation_results = evaluator.evaluate_model(X_test, y_test)\n",
    "\n",
    "# Plot results\n",
    "evaluator.plot_confusion_matrix(y_test, evaluation_results['predictions'])\n",
    "evaluator.plot_per_genre_performance(evaluation_results['classification_report'])\n",
    "\n",
    "print(\"\\n‚úÖ Evaluation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_path = model_manager.save_model(trainer, embedding_gen, config, evaluation_results['metrics'])\n",
    "print(f\"üíæ Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Production-Ready Prediction Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieGenrePredictor:\n",
    "    \"\"\"Production-ready prediction interface\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str = None):\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        \n",
    "        if model_path:\n",
    "            self.load_model(model_path)\n",
    "        else:\n",
    "            # Use current session models\n",
    "            self.classifier = trainer.best_model\n",
    "            self.label_encoder = trainer.label_encoder\n",
    "            self.embedding_model = embedding_gen.model\n",
    "            self.config = config\n",
    "    \n",
    "    def load_model(self, model_path: str):\n",
    "        \"\"\"Load saved model\"\"\"\n",
    "        self.classifier, self.label_encoder, metadata = model_manager.load_model(model_path)\n",
    "        \n",
    "        # Load embedding model\n",
    "        embedding_model_name = metadata['config']['embedding_model']\n",
    "        self.embedding_model = SentenceTransformer(embedding_model_name)\n",
    "        \n",
    "        if device.type == 'cuda':\n",
    "            self.embedding_model = self.embedding_model.to(device)\n",
    "    \n",
    "    def predict(self, plot_description: str, return_probabilities: bool = True, \n",
    "               top_n: int = 3) -> Dict:\n",
    "        \"\"\"Predict movie genre with confidence scores\"\"\"\n",
    "        try:\n",
    "            # Validate input\n",
    "            if not plot_description or len(plot_description.strip()) < 10:\n",
    "                raise ValueError(\"Plot description too short (minimum 10 characters)\")\n",
    "            \n",
    "            # Generate embedding\n",
    "            plot_embedding = self.embedding_model.encode(\n",
    "                [plot_description], \n",
    "                device=device.type,\n",
    "                normalize_embeddings=True\n",
    "            )\n",
    "            \n",
    "            # Get prediction\n",
    "            prediction = self.classifier.predict(plot_embedding)[0]\n",
    "            predicted_genre = self.label_encoder.classes_[prediction]\n",
    "            \n",
    "            result = {\n",
    "                'predicted_genre': predicted_genre,\n",
    "                'plot': plot_description[:100] + '...' if len(plot_description) > 100 else plot_description\n",
    "            }\n",
    "            \n",
    "            if return_probabilities:\n",
    "                probabilities = self.classifier.predict_proba(plot_embedding)[0]\n",
    "                top_indices = np.argsort(probabilities)[::-1][:top_n]\n",
    "                \n",
    "                result['confidence_scores'] = []\n",
    "                for idx in top_indices:\n",
    "                    genre = self.label_encoder.classes_[idx]\n",
    "                    confidence = probabilities[idx]\n",
    "                    result['confidence_scores'].append({\n",
    "                        'genre': genre,\n",
    "                        'confidence': float(confidence)\n",
    "                    })\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Prediction failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def predict_batch(self, plot_descriptions: List[str]) -> List[Dict]:\n",
    "        \"\"\"Batch prediction for multiple plots\"\"\"\n",
    "        return [self.predict(plot) for plot in plot_descriptions]\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = MovieGenrePredictor()\n",
    "print(\"‚úÖ Production predictor ready!\")\n",
    "\n",
    "# Quick test with one example\n",
    "test_plot = \"A young wizard discovers his magical heritage and attends a school for magic\"\n",
    "result = predictor.predict(test_plot, top_n=3)\n",
    "\n",
    "print(f\"\\nüé¨ Quick Test:\")\n",
    "print(f\"Plot: {result['plot']}\")\n",
    "print(f\"üéØ Predicted: {result['predicted_genre']} ({result['confidence_scores'][0]['confidence']:.1%})\")\n",
    "\n",
    "print(f\"\\n‚úÖ Predictor working! Use interactive_movie_testing() for more tests.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéÆ Interactive Testing Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_movie_testing():\n",
    "    \"\"\"Interactive testing interface\"\"\"\n",
    "    # Check if all required variables are available\n",
    "    required_vars = ['trainer', 'embedding_gen', 'X_test', 'y_test', 'X_train', 'evaluation_results']\n",
    "    missing_vars = [var for var in required_vars if var not in globals()]\n",
    "    \n",
    "    if missing_vars:\n",
    "        print(f\"‚ùå Error: Missing required variables: {', '.join(missing_vars)}\")\n",
    "        print(\"üí° Please run all previous cells first to train the model!\")\n",
    "        print(\"üîÑ Make sure you've completed the training pipeline before testing.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüéÆ INTERACTIVE MOVIE GENRE PREDICTION\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"üé¨ Enter movie plots to see AI predictions!\")\n",
    "    print(\"üí° Type 'quit' to exit, 'stats' for model performance\")\n",
    "    print()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            plot = input(\"üé¨ Enter movie plot (or 'quit'/'stats'): \").strip()\n",
    "            \n",
    "            if plot.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"üëã Thanks for testing!\")\n",
    "                break\n",
    "            \n",
    "            if plot.lower() == 'stats':\n",
    "                print(f\"\\nüìä MODEL PERFORMANCE:\")\n",
    "                print(f\"   üéØ Test Accuracy: {evaluation_results['metrics']['accuracy']:.1%}\")\n",
    "                print(f\"   üìà Precision: {evaluation_results['metrics']['precision']:.3f}\")\n",
    "                print(f\"   üìâ Recall: {evaluation_results['metrics']['recall']:.3f}\")\n",
    "                print(f\"   üé™ F1-Score: {evaluation_results['metrics']['f1_score']:.3f}\")\n",
    "                print(f\"   üé≠ Genres: {len(trainer.label_encoder.classes_)}\")\n",
    "                print(f\"   üìö Training samples: {len(X_train)}\")\n",
    "                print(f\"   üß™ Test samples: {len(X_test)}\")\n",
    "                continue\n",
    "            \n",
    "            if len(plot) < 10:\n",
    "                print(\"‚ö†Ô∏è Please enter a longer plot (at least 10 characters)\")\n",
    "                continue\n",
    "            \n",
    "            # Make prediction\n",
    "            result = predictor.predict(plot, top_n=5)\n",
    "            \n",
    "            print(f\"\\nü§ñ AI Analysis:\")\n",
    "            print(f\"üéØ Predicted Genre: {result['predicted_genre']}\")\n",
    "            print(f\"üìä Confidence Breakdown:\")\n",
    "            \n",
    "            for i, score in enumerate(result['confidence_scores']):\n",
    "                emoji = \"ü•á\" if i == 0 else \"ü•à\" if i == 1 else \"ü•â\" if i == 2 else f\"{i+1}.\"\n",
    "                bar_length = int(score['confidence'] * 20)\n",
    "                bar = \"‚ñà\" * bar_length + \"‚ñë\" * (20 - bar_length)\n",
    "                print(f\"   {emoji} {score['genre']:<15} {bar} {score['confidence']:.3f} ({score['confidence']*100:.1f}%)\")\n",
    "            \n",
    "            print()\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüëã Session interrupted. Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            print(\"üí° Please try again with a different plot.\")\n",
    "\n",
    "# ‚ö†Ô∏è IMPORTANT: Uncomment the line below to start interactive testing\n",
    "# NOTE: Make sure you've run all previous cells first!\n",
    "# interactive_movie_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üöÄ Deployment Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check deployment dependencies (already installed in Cell 2)\n",
    "deployment_packages = ['skl2onnx', 'onnx', 'onnxruntime']\n",
    "\n",
    "all_available = True\n",
    "for package in deployment_packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        all_available = False\n",
    "        break\n",
    "\n",
    "if all_available:\n",
    "    print(\"‚úÖ All deployment dependencies available!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Some deployment dependencies missing. Run Cell 2 to install all packages.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert trained model to ONNX format for deployment\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "def convert_model_to_onnx(classifier, output_path=\"movie_genre_classifier.onnx\"):\n",
    "    \"\"\"Convert sklearn model to ONNX format for deployment\"\"\"\n",
    "    try:\n",
    "        initial_type = [('float_input', FloatTensorType([None, 768]))]\n",
    "        onnx_model = convert_sklearn(classifier, initial_types=initial_type)\n",
    "        \n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(onnx_model.SerializeToString())\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ONNX conversion failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Convert the best classifier to ONNX\n",
    "if 'trainer' in globals() and trainer.best_model is not None:\n",
    "    onnx_path = convert_model_to_onnx(trainer.best_model)\n",
    "    print(f\"‚úÖ ONNX model saved: {onnx_path}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No trained model found. Run the training pipeline first!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üéØ Next Steps: Production Deployment\n",
    "\n",
    "### **üè≠ For OpenShift AI Model Serving:**\n",
    "1. **Upload ONNX model** to MinIO or S3 storage\n",
    "2. **Create InferenceService** with multi-model serving platform  \n",
    "3. **Deploy Flask web app** for user interface\n",
    "4. **Set up monitoring** and model management\n",
    "\n",
    "### **üìö Deployment Resources:**\n",
    "- **Complete Guide**: See `openshift_ai_movie_blog.txt` for full deployment walkthrough\n",
    "- **MinIO Setup**: S3-compatible storage configuration\n",
    "- **Model Serving**: ONNX model deployment on OpenShift AI\n",
    "- **Web App**: Containerized Flask application with UI\n",
    "\n",
    "### **üõ†Ô∏è Alternative Deployments:**\n",
    "- **Local API**: Use `predictor.predict()` in Flask/FastAPI\n",
    "- **Batch Processing**: Use `predictor.predict_batch()` for bulk predictions  \n",
    "- **Cloud Platforms**: Deploy to AWS SageMaker, Azure ML, or GCP AI Platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ IMPROVED MPNET MOVIE CLASSIFIER - COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üèÜ Final Performance:\")\n",
    "print(f\"   ‚Ä¢ Test Accuracy: {evaluation_results['metrics']['accuracy']:.1%}\")\n",
    "print(f\"   ‚Ä¢ Precision: {evaluation_results['metrics']['precision']:.3f}\")\n",
    "print(f\"   ‚Ä¢ Recall: {evaluation_results['metrics']['recall']:.3f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score: {evaluation_results['metrics']['f1_score']:.3f}\")\n",
    "print(f\"\\nüîß Technical Improvements:\")\n",
    "print(f\"   ‚úÖ Security: Replaced eval() with json.loads()\")\n",
    "print(f\"   ‚úÖ Modularity: Separated into classes and modules\")\n",
    "print(f\"   ‚úÖ Error Handling: Comprehensive validation\")\n",
    "print(f\"   ‚úÖ Model Persistence: Save/load functionality\")\n",
    "print(f\"   ‚úÖ Configuration: YAML-based config management\")\n",
    "print(f\"   ‚úÖ Cross-Validation: {config.training.cv_folds}-fold CV with hyperparameter tuning\")\n",
    "print(f\"   ‚úÖ Logging: Structured logging system\")\n",
    "print(f\"   ‚úÖ Performance: Optimized embeddings with caching\")\n",
    "print(f\"\\nüíæ Model saved to: {model_path}\")\n",
    "print(f\"\\nüöÄ Ready for Production:\")\n",
    "print(f\"   ‚Ä¢ Call predictor.predict('your plot') for single predictions\")\n",
    "print(f\"   ‚Ä¢ Call predictor.predict_batch([plots]) for batch predictions\")\n",
    "print(f\"   ‚Ä¢ Call interactive_movie_testing() for interactive mode\")\n",
    "print(f\"   ‚Ä¢ Model can be loaded with MovieGenrePredictor(model_path)\")\n",
    "print(f\"\\nüìà Next Steps:\")\n",
    "print(f\"   ‚Ä¢ Run deployment preparation cells (Cell 29-30) for ONNX conversion\")\n",
    "print(f\"   ‚Ä¢ Follow openshift_ai_movie_blog.txt for OpenShift AI deployment\")  \n",
    "print(f\"   ‚Ä¢ Deploy as REST API with Flask/FastAPI\")\n",
    "print(f\"   ‚Ä¢ Add A/B testing framework\")\n",
    "print(f\"   ‚Ä¢ Implement model monitoring\")\n",
    "print(f\"   ‚Ä¢ Add data drift detection\")\n",
    "print(f\"   ‚Ä¢ Create automated retraining pipeline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
