{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¬ Improved MPNet Movie Genre Classification\n",
    "## Production-Ready Implementation with Security, Modularity & Performance\n",
    "\n",
    "### Key Improvements:\n",
    "- âœ… **Security**: Replaced `eval()` with `json.loads()`\n",
    "- âœ… **Modularity**: Separated concerns into classes\n",
    "- âœ… **Error Handling**: Comprehensive validation and error handling\n",
    "- âœ… **Model Persistence**: Save/load trained models\n",
    "- âœ… **Configuration**: YAML-based configuration management\n",
    "- âœ… **Cross-Validation**: Robust model evaluation\n",
    "- âœ… **Logging**: Proper logging instead of print statements\n",
    "- âœ… **Performance**: Optimized embeddings and caching\n",
    "\n",
    "**Accuracy Target**: 55%+ (vs original 54.3%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Installation & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package with verbose output\"\"\"\n",
    "    try:\n",
    "        print(f\"   Running: pip install {package}\")\n",
    "        result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", package], \n",
    "                               check=True, text=True)\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"   âŒ Installation failed: {e}\")\n",
    "        return False\n",
    "\n",
    "required_packages = [\n",
    "    'sentence-transformers>=2.2.0',\n",
    "    'scikit-learn>=1.3.0', \n",
    "    'xgboost>=1.7.0',\n",
    "    'pandas>=2.0.0',\n",
    "    'numpy>=1.24.0',\n",
    "    'matplotlib>=3.7.0',\n",
    "    'seaborn>=0.12.0',\n",
    "    'tqdm>=4.65.0',\n",
    "    'pyyaml>=6.0',\n",
    "    'joblib>=1.3.0',\n",
    "    'flask>=2.3.0',\n",
    "    'skl2onnx==1.15.0',\n",
    "    'onnx==1.14.1',\n",
    "    'onnxruntime==1.15.1'\n",
    "]\n",
    "\n",
    "missing_packages = []\n",
    "for package in required_packages:\n",
    "    package_name = package.split('>=')[0].split('==')[0]\n",
    "    try:\n",
    "        # Handle special import names\n",
    "        if package_name == 'sentence-transformers':\n",
    "            import sentence_transformers\n",
    "        elif package_name == 'scikit-learn':\n",
    "            import sklearn\n",
    "        elif package_name == 'pyyaml':\n",
    "            import yaml\n",
    "        else:\n",
    "            __import__(package_name.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"ğŸ“¦ Installing {len(missing_packages)} missing packages...\")\n",
    "    for package in missing_packages:\n",
    "        if not install_package(package):\n",
    "            print(f\"âŒ Failed to install {package}\")\n",
    "    print(\"âœ… Installation complete!\")\n",
    "else:\n",
    "    print(\"âœ… All packages already installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Configuration Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "import os\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    name: str\n",
    "    embedding_model: str\n",
    "    embedding_dim: int\n",
    "    max_seq_length: int\n",
    "    batch_size: int\n",
    "    normalize_embeddings: bool\n",
    "\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "    dataset_path: str\n",
    "    min_plot_length: int\n",
    "    max_genres: int\n",
    "    test_size: float\n",
    "    random_state: int\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    cv_folds: int\n",
    "    n_jobs: int\n",
    "    scoring: str\n",
    "    classifiers: Dict\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    model: ModelConfig\n",
    "    data: DataConfig\n",
    "    training: TrainingConfig\n",
    "    output_dir: str\n",
    "    logging_level: str\n",
    "\n",
    "# Default configuration\n",
    "default_config = {\n",
    "    'model': {\n",
    "        'name': 'mpnet-movie-classifier',\n",
    "        'embedding_model': 'all-mpnet-base-v2',\n",
    "        'embedding_dim': 768,\n",
    "        'max_seq_length': 512,\n",
    "        'batch_size': 32,\n",
    "        'normalize_embeddings': True\n",
    "    },\n",
    "    'data': {\n",
    "        'dataset_path': 'tmdb_5000_movies.csv',\n",
    "        'min_plot_length': 50,\n",
    "        'max_genres': 8,\n",
    "        'test_size': 0.2,\n",
    "        'random_state': 42\n",
    "    },\n",
    "    'training': {\n",
    "        'cv_folds': 5,\n",
    "        'n_jobs': -1,\n",
    "        'scoring': 'accuracy',\n",
    "        'classifiers': {\n",
    "            'RandomForest': {\n",
    "                'n_estimators': [200],\n",
    "                'max_depth': [20],\n",
    "                'min_samples_split': [2]\n",
    "            },\n",
    "            'LogisticRegression': {\n",
    "                'C': [1.0],\n",
    "                'max_iter': [2000]\n",
    "            },\n",
    "            'XGBoost': {\n",
    "                'n_estimators': [100],\n",
    "                'max_depth': [6],\n",
    "                'learning_rate': [0.1]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'output_dir': 'models',\n",
    "    'logging_level': 'INFO'\n",
    "}\n",
    "\n",
    "def load_config(config_path: Optional[str] = None) -> Config:\n",
    "    \"\"\"Load configuration from YAML file or use defaults\"\"\"\n",
    "    if config_path and os.path.exists(config_path):\n",
    "        with open(config_path, 'r') as f:\n",
    "            config_dict = yaml.safe_load(f)\n",
    "    else:\n",
    "        config_dict = default_config\n",
    "    \n",
    "    return Config(\n",
    "        model=ModelConfig(**config_dict['model']),\n",
    "        data=DataConfig(**config_dict['data']),\n",
    "        training=TrainingConfig(**config_dict['training']),\n",
    "        output_dir=config_dict['output_dir'],\n",
    "        logging_level=config_dict['logging_level']\n",
    "    )\n",
    "\n",
    "config = load_config()\n",
    "print(\"âœ… Configuration loaded\")\n",
    "print(f\"ğŸ“Š Model: {config.model.embedding_model}\")\n",
    "print(f\"ğŸ“ Dataset: {config.data.dataset_path}\")\n",
    "print(f\"ğŸ¯ Max genres: {config.data.max_genres}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=getattr(logging, config.logging_level),\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler(f'movie_classifier_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"ğŸ¬ Starting MPNet Movie Genre Classification\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(config.output_dir, exist_ok=True)\n",
    "logger.info(f\"ğŸ“ Output directory: {config.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import Tuple, Union, List, Dict, Any\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML imports\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, \n",
    "    precision_recall_fscore_support, roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    HAS_XGBOOST = True\n",
    "    logger.info(\"âœ… XGBoost available\")\n",
    "except ImportError:\n",
    "    HAS_XGBOOST = False\n",
    "    logger.warning(\"âš ï¸ XGBoost not available\")\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"ğŸ”§ Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"ğŸš€ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"Secure and robust data processing pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, config: DataConfig):\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def load_dataset(self) -> pd.DataFrame:\n",
    "        \"\"\"Load and validate dataset\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(self.config.dataset_path)\n",
    "            self.logger.info(f\"ğŸ“‚ Dataset loaded: {df.shape}\")\n",
    "            return df\n",
    "        except FileNotFoundError:\n",
    "            self.logger.error(f\"âŒ Dataset not found: {self.config.dataset_path}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"âŒ Error loading dataset: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def extract_primary_genre(self, genres_str: str) -> Optional[str]:\n",
    "        \"\"\"Safely extract primary genre using json.loads instead of eval\"\"\"\n",
    "        if pd.isna(genres_str) or not genres_str.strip():\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Handle string format issues\n",
    "            genres_str = genres_str.replace(\"'\", '\"')  # Convert single quotes to double quotes\n",
    "            genres_list = json.loads(genres_str)\n",
    "            \n",
    "            if isinstance(genres_list, list) and len(genres_list) > 0:\n",
    "                if isinstance(genres_list[0], dict) and 'name' in genres_list[0]:\n",
    "                    return genres_list[0]['name']\n",
    "        except (json.JSONDecodeError, KeyError, IndexError, TypeError) as e:\n",
    "            self.logger.debug(f\"Failed to parse genre: {genres_str[:50]}... Error: {e}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def validate_text(self, text: str) -> bool:\n",
    "        \"\"\"Validate text quality\"\"\"\n",
    "        if pd.isna(text) or not isinstance(text, str):\n",
    "            return False\n",
    "        \n",
    "        # Check minimum length\n",
    "        if len(text.strip()) < self.config.min_plot_length:\n",
    "            return False\n",
    "        \n",
    "        # Check for meaningful content (not just special characters)\n",
    "        if not any(c.isalnum() for c in text):\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def process_dataset(self, df: pd.DataFrame) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"Process dataset with comprehensive validation\"\"\"\n",
    "        self.logger.info(\"ğŸ”§ Processing dataset...\")\n",
    "        \n",
    "        # Check required columns\n",
    "        required_cols = ['overview', 'genres']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Clean data\n",
    "        df_clean = df.dropna(subset=['overview', 'genres']).copy()\n",
    "        self.logger.info(f\"ğŸ“Š After removing NaN: {len(df_clean)} movies\")\n",
    "        \n",
    "        # Extract genres safely\n",
    "        df_clean['primary_genre'] = df_clean['genres'].apply(self.extract_primary_genre)\n",
    "        df_clean = df_clean.dropna(subset=['primary_genre'])\n",
    "        self.logger.info(f\"ğŸ“Š After genre extraction: {len(df_clean)} movies\")\n",
    "        \n",
    "        # Validate text quality\n",
    "        valid_mask = df_clean['overview'].apply(self.validate_text)\n",
    "        df_clean = df_clean[valid_mask]\n",
    "        self.logger.info(f\"ğŸ“Š After text validation: {len(df_clean)} movies\")\n",
    "        \n",
    "        if len(df_clean) == 0:\n",
    "            raise ValueError(\"No valid data remaining after processing\")\n",
    "        \n",
    "        # Select top genres\n",
    "        genre_counts = df_clean['primary_genre'].value_counts()\n",
    "        self.logger.info(f\"ğŸ­ Genre distribution:\\n{genre_counts.head(10)}\")\n",
    "        \n",
    "        top_genres = genre_counts.head(self.config.max_genres).index.tolist()\n",
    "        df_final = df_clean[df_clean['primary_genre'].isin(top_genres)].copy()\n",
    "        \n",
    "        self.logger.info(f\"ğŸ¯ Final dataset: {len(df_final)} movies, {len(top_genres)} genres\")\n",
    "        \n",
    "        # Prepare output\n",
    "        texts = df_final['overview'].tolist()\n",
    "        labels = df_final['primary_genre'].tolist()\n",
    "        \n",
    "        # Log statistics\n",
    "        avg_length = np.mean([len(text.split()) for text in texts])\n",
    "        self.logger.info(f\"ğŸ“Š Average plot length: {avg_length:.1f} words\")\n",
    "        \n",
    "        return texts, labels\n",
    "\n",
    "# Initialize processor\n",
    "processor = DataProcessor(config.data)\n",
    "print(\"âœ… Data processor initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  Embedding Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingGenerator:\n",
    "    \"\"\"Optimized embedding generation with caching\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.model = None\n",
    "        self._cache = {}\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load embedding model\"\"\"\n",
    "        self.logger.info(f\"ğŸ§  Loading {self.config.embedding_model}...\")\n",
    "        \n",
    "        try:\n",
    "            self.model = SentenceTransformer(self.config.embedding_model)\n",
    "            \n",
    "            # Move to GPU if available\n",
    "            if device.type == 'cuda':\n",
    "                self.model = self.model.to(device)\n",
    "                self.logger.info(\"ğŸš€ Model moved to GPU\")\n",
    "            \n",
    "            # Log model info\n",
    "            self.logger.info(f\"âœ… Model loaded: {self.config.embedding_model}\")\n",
    "            self.logger.info(f\"ğŸ“ Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "            self.logger.info(f\"ğŸ“ Max sequence length: {self.model.max_seq_length}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"âŒ Failed to load model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def generate_embeddings(self, texts: List[str], use_cache: bool = True) -> np.ndarray:\n",
    "        \"\"\"Generate embeddings with progress tracking and caching\"\"\"\n",
    "        if self.model is None:\n",
    "            self.load_model()\n",
    "        \n",
    "        cache_key = hash(tuple(texts)) if use_cache else None\n",
    "        \n",
    "        if use_cache and cache_key in self._cache:\n",
    "            self.logger.info(\"ğŸ“‹ Using cached embeddings\")\n",
    "            return self._cache[cache_key]\n",
    "        \n",
    "        self.logger.info(f\"ğŸ”„ Generating embeddings for {len(texts)} texts...\")\n",
    "        self.logger.info(\"â° This might take a few minutes, but it's worth the wait...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            embeddings = self.model.encode(\n",
    "                texts,\n",
    "                batch_size=self.config.batch_size,\n",
    "                show_progress_bar=True,\n",
    "                device=device.type,\n",
    "                normalize_embeddings=self.config.normalize_embeddings,\n",
    "                convert_to_numpy=True\n",
    "            )\n",
    "            \n",
    "            duration = time.time() - start_time\n",
    "            self.logger.info(f\"âœ… Embeddings generated in {duration:.2f}s\")\n",
    "            self.logger.info(f\"ğŸ“Š Shape: {embeddings.shape}\")\n",
    "            self.logger.info(f\"ğŸ’¾ Memory: {embeddings.nbytes / 1e6:.1f}MB\")\n",
    "            \n",
    "            if use_cache:\n",
    "                self._cache[cache_key] = embeddings\n",
    "            \n",
    "            return embeddings\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"âŒ Failed to generate embeddings: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def clear_cache(self):\n",
    "        \"\"\"Clear embedding cache\"\"\"\n",
    "        self._cache.clear()\n",
    "        self.logger.info(\"ğŸ—‘ï¸ Cache cleared\")\n",
    "\n",
    "# Initialize embedding generator\n",
    "embedding_gen = EmbeddingGenerator(config.model)\n",
    "print(\"âœ… Embedding generator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‹ï¸ Enhanced Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"Advanced model training with cross-validation and hyperparameter tuning\"\"\"\n",
    "    \n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.best_model = None\n",
    "        self.best_params = None\n",
    "        self.results = {}\n",
    "    \n",
    "    def prepare_data(self, embeddings: np.ndarray, labels: List[str]) -> Tuple:\n",
    "        \"\"\"Prepare data for training with class balancing\"\"\"\n",
    "        self.logger.info(\"ğŸ“š Preparing training data...\")\n",
    "        \n",
    "        # Encode labels\n",
    "        encoded_labels = self.label_encoder.fit_transform(labels)\n",
    "        \n",
    "        # Log label mapping\n",
    "        self.logger.info(\"ğŸ·ï¸ Label mapping:\")\n",
    "        for i, genre in enumerate(self.label_encoder.classes_):\n",
    "            count = (encoded_labels == i).sum()\n",
    "            self.logger.info(f\"  â€¢ {genre}: {count} movies (label {i})\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            embeddings, \n",
    "            encoded_labels, \n",
    "            test_size=config.data.test_size, \n",
    "            random_state=config.data.random_state,\n",
    "            stratify=encoded_labels\n",
    "        )\n",
    "        \n",
    "        self.logger.info(f\"ğŸ“Š Training: {len(X_train)}, Testing: {len(X_test)}\")\n",
    "        \n",
    "        # Compute class weights for balanced training\n",
    "        class_weights = compute_class_weight(\n",
    "            'balanced', \n",
    "            classes=np.unique(y_train), \n",
    "            y=y_train\n",
    "        )\n",
    "        self.class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def get_classifiers(self) -> Dict:\n",
    "        \"\"\"Get classifiers with hyperparameter grids\"\"\"\n",
    "        classifiers = {\n",
    "            'RandomForest': (\n",
    "                RandomForestClassifier(\n",
    "                    random_state=config.data.random_state,\n",
    "                    n_jobs=self.config.n_jobs,\n",
    "                    class_weight='balanced'\n",
    "                ),\n",
    "                self.config.classifiers.get('RandomForest', {})\n",
    "            ),\n",
    "            'LogisticRegression': (\n",
    "                LogisticRegression(\n",
    "                    random_state=config.data.random_state,\n",
    "                    class_weight='balanced',\n",
    "                    n_jobs=self.config.n_jobs\n",
    "                ),\n",
    "                self.config.classifiers.get('LogisticRegression', {})\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        if HAS_XGBOOST:\n",
    "            classifiers['XGBoost'] = (\n",
    "                xgb.XGBClassifier(\n",
    "                    random_state=config.data.random_state,\n",
    "                    eval_metric='mlogloss',\n",
    "                    n_jobs=self.config.n_jobs\n",
    "                ),\n",
    "                self.config.classifiers.get('XGBoost', {})\n",
    "            )\n",
    "        \n",
    "        return classifiers\n",
    "    \n",
    "    def train_with_cv(self, X_train: np.ndarray, y_train: np.ndarray) -> Dict:\n",
    "        \"\"\"Train models with cross-validation and hyperparameter tuning\"\"\"\n",
    "        self.logger.info(\"ğŸ‹ï¸ Training models with cross-validation...\")\n",
    "        self.logger.info(\"â° Note: This training step will take 1-2 minutes - optimized for speed! â˜•\")\n",
    "        \n",
    "        classifiers = self.get_classifiers()\n",
    "        cv = StratifiedKFold(n_splits=self.config.cv_folds, shuffle=True, \n",
    "                           random_state=config.data.random_state)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for name, (classifier, param_grid) in classifiers.items():\n",
    "            self.logger.info(f\"ğŸ”„ Training {name}...\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                if param_grid:  # Hyperparameter tuning\n",
    "                    grid_search = GridSearchCV(\n",
    "                        classifier,\n",
    "                        param_grid,\n",
    "                        cv=cv,\n",
    "                        scoring=self.config.scoring,\n",
    "                        n_jobs=self.config.n_jobs,\n",
    "                        verbose=0\n",
    "                    )\n",
    "                    grid_search.fit(X_train, y_train)\n",
    "                    \n",
    "                    best_estimator = grid_search.best_estimator_\n",
    "                    best_score = grid_search.best_score_\n",
    "                    best_params = grid_search.best_params_\n",
    "                    \n",
    "                else:  # Default parameters\n",
    "                    scores = cross_val_score(classifier, X_train, y_train, \n",
    "                                           cv=cv, scoring=self.config.scoring)\n",
    "                    classifier.fit(X_train, y_train)\n",
    "                    \n",
    "                    best_estimator = classifier\n",
    "                    best_score = scores.mean()\n",
    "                    best_params = {}\n",
    "                \n",
    "                duration = time.time() - start_time\n",
    "                \n",
    "                results[name] = {\n",
    "                    'model': best_estimator,\n",
    "                    'cv_score': best_score,\n",
    "                    'cv_std': 0,  # Will be calculated properly if needed\n",
    "                    'best_params': best_params,\n",
    "                    'training_time': duration\n",
    "                }\n",
    "                \n",
    "                self.logger.info(f\"âœ… {name}: CV Score = {best_score:.3f} ({duration:.1f}s)\")\n",
    "                if best_params:\n",
    "                    self.logger.info(f\"   Best params: {best_params}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"âŒ Failed to train {name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Find best model\n",
    "        if results:\n",
    "            best_name = max(results, key=lambda x: results[x]['cv_score'])\n",
    "            self.best_model = results[best_name]['model']\n",
    "            self.best_params = results[best_name]['best_params']\n",
    "            \n",
    "            self.logger.info(f\"ğŸ† Best model: {best_name} (CV: {results[best_name]['cv_score']:.3f})\")\n",
    "        \n",
    "        self.results = results\n",
    "        return results\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = ModelTrainer(config.training)\n",
    "print(\"âœ… Model trainer initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    \"\"\"Handle model saving and loading with metadata\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: str):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def save_model(self, trainer: ModelTrainer, embedding_gen: EmbeddingGenerator, \n",
    "                  config: Config, metrics: Dict) -> str:\n",
    "        \"\"\"Save complete model pipeline with metadata\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        model_dir = self.output_dir / f\"model_{timestamp}\"\n",
    "        model_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            # Save best model\n",
    "            joblib.dump(trainer.best_model, model_dir / \"classifier.pkl\")\n",
    "            \n",
    "            # Save label encoder\n",
    "            joblib.dump(trainer.label_encoder, model_dir / \"label_encoder.pkl\")\n",
    "            \n",
    "            # Save metadata\n",
    "            metadata = {\n",
    "                'timestamp': timestamp,\n",
    "                'config': {\n",
    "                    'embedding_model': config.model.embedding_model,\n",
    "                    'max_genres': config.data.max_genres,\n",
    "                    'test_size': config.data.test_size\n",
    "                },\n",
    "                'best_params': trainer.best_params,\n",
    "                'metrics': metrics,\n",
    "                'label_classes': trainer.label_encoder.classes_.tolist()\n",
    "            }\n",
    "            \n",
    "            with open(model_dir / \"metadata.json\", 'w') as f:\n",
    "                json.dump(metadata, f, indent=2, default=str)\n",
    "            \n",
    "            # Save config\n",
    "            with open(model_dir / \"config.yaml\", 'w') as f:\n",
    "                yaml.dump(default_config, f, default_flow_style=False)\n",
    "            \n",
    "            self.logger.info(f\"ğŸ’¾ Model saved to {model_dir}\")\n",
    "            return str(model_dir)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"âŒ Failed to save model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def load_model(self, model_path: str) -> Tuple:\n",
    "        \"\"\"Load complete model pipeline\"\"\"\n",
    "        model_dir = Path(model_path)\n",
    "        \n",
    "        try:\n",
    "            # Load model components\n",
    "            classifier = joblib.load(model_dir / \"classifier.pkl\")\n",
    "            label_encoder = joblib.load(model_dir / \"label_encoder.pkl\")\n",
    "            \n",
    "            # Load metadata\n",
    "            with open(model_dir / \"metadata.json\", 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "            \n",
    "            self.logger.info(f\"ğŸ“‚ Model loaded from {model_dir}\")\n",
    "            return classifier, label_encoder, metadata\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"âŒ Failed to load model: {e}\")\n",
    "            raise\n",
    "\n",
    "# Initialize model manager\n",
    "model_manager = ModelManager(config.output_dir)\n",
    "print(\"âœ… Model manager initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Main Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "logger.info(\"ğŸ“Š Starting data processing pipeline...\")\n",
    "df = processor.load_dataset()\n",
    "texts, labels = processor.process_dataset(df)\n",
    "\n",
    "# Generate embeddings\n",
    "logger.info(\"ğŸ§  Generating embeddings...\")\n",
    "embeddings = embedding_gen.generate_embeddings(texts)\n",
    "\n",
    "# Prepare training data\n",
    "X_train, X_test, y_train, y_test = trainer.prepare_data(embeddings, labels)\n",
    "\n",
    "# Train models\n",
    "logger.info(\"ğŸ‹ï¸ Training models...\")\n",
    "training_results = trainer.train_with_cv(X_train, y_train)\n",
    "\n",
    "print(\"\\nğŸ‰ Training pipeline completed!\")\n",
    "print(f\"ğŸ“Š Results summary:\")\n",
    "for name, result in training_results.items():\n",
    "    print(f\"  â€¢ {name}: {result['cv_score']:.3f} ({result['training_time']:.1f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Enhanced Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    \n",
    "    def __init__(self, trainer: ModelTrainer):\n",
    "        self.trainer = trainer\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def evaluate_model(self, X_test: np.ndarray, y_test: np.ndarray) -> Dict:\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        self.logger.info(\"ğŸ“Š Evaluating best model...\")\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = self.trainer.best_model.predict(X_test)\n",
    "        y_pred_proba = self.trainer.best_model.predict_proba(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        }\n",
    "        \n",
    "        # Classification report\n",
    "        target_names = self.trainer.label_encoder.classes_\n",
    "        class_report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "        \n",
    "        self.logger.info(f\"ğŸ¯ Test Accuracy: {accuracy:.3f} ({accuracy*100:.1f}%)\")\n",
    "        self.logger.info(f\"ğŸ“Š Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "        \n",
    "        return {\n",
    "            'metrics': metrics,\n",
    "            'classification_report': class_report,\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_pred_proba\n",
    "        }\n",
    "    \n",
    "    def plot_confusion_matrix(self, y_test: np.ndarray, y_pred: np.ndarray, save_path: str = None):\n",
    "        \"\"\"Plot enhanced confusion matrix\"\"\"\n",
    "        target_names = self.trainer.label_encoder.classes_\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=target_names, yticklabels=target_names,\n",
    "                   cbar_kws={'label': 'Count'})\n",
    "        \n",
    "        plt.title(f'Confusion Matrix - MPNet Movie Genre Classifier\\nTest Accuracy: {accuracy_score(y_test, y_pred):.1%}', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Predicted Genre', fontsize=12)\n",
    "        plt.ylabel('True Genre', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            self.logger.info(f\"ğŸ“Š Confusion matrix saved to {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def plot_per_genre_performance(self, class_report: Dict, save_path: str = None):\n",
    "        \"\"\"Plot per-genre performance metrics\"\"\"\n",
    "        genres = [k for k in class_report.keys() if k not in ['accuracy', 'macro avg', 'weighted avg']]\n",
    "        \n",
    "        metrics_data = {\n",
    "            'Genre': genres,\n",
    "            'Precision': [class_report[g]['precision'] for g in genres],\n",
    "            'Recall': [class_report[g]['recall'] for g in genres],\n",
    "            'F1-Score': [class_report[g]['f1-score'] for g in genres],\n",
    "            'Support': [class_report[g]['support'] for g in genres]\n",
    "        }\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Precision\n",
    "        axes[0,0].bar(metrics_data['Genre'], metrics_data['Precision'], color='skyblue')\n",
    "        axes[0,0].set_title('Precision by Genre')\n",
    "        axes[0,0].set_ylim(0, 1)\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Recall\n",
    "        axes[0,1].bar(metrics_data['Genre'], metrics_data['Recall'], color='lightcoral')\n",
    "        axes[0,1].set_title('Recall by Genre')\n",
    "        axes[0,1].set_ylim(0, 1)\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # F1-Score\n",
    "        axes[1,0].bar(metrics_data['Genre'], metrics_data['F1-Score'], color='lightgreen')\n",
    "        axes[1,0].set_title('F1-Score by Genre')\n",
    "        axes[1,0].set_ylim(0, 1)\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Support\n",
    "        axes[1,1].bar(metrics_data['Genre'], metrics_data['Support'], color='gold')\n",
    "        axes[1,1].set_title('Support (Number of Samples) by Genre')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            self.logger.info(f\"ğŸ“Š Performance plot saved to {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = ModelEvaluator(trainer)\n",
    "evaluation_results = evaluator.evaluate_model(X_test, y_test)\n",
    "\n",
    "# Plot results\n",
    "evaluator.plot_confusion_matrix(y_test, evaluation_results['predictions'])\n",
    "evaluator.plot_per_genre_performance(evaluation_results['classification_report'])\n",
    "\n",
    "print(\"\\nâœ… Evaluation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_path = model_manager.save_model(trainer, embedding_gen, config, evaluation_results['metrics'])\n",
    "print(f\"ğŸ’¾ Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª Production-Ready Prediction Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieGenrePredictor:\n",
    "    \"\"\"Production-ready prediction interface\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str = None):\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        \n",
    "        if model_path:\n",
    "            self.load_model(model_path)\n",
    "        else:\n",
    "            # Use current session models\n",
    "            self.classifier = trainer.best_model\n",
    "            self.label_encoder = trainer.label_encoder\n",
    "            self.embedding_model = embedding_gen.model\n",
    "            self.config = config\n",
    "    \n",
    "    def load_model(self, model_path: str):\n",
    "        \"\"\"Load saved model\"\"\"\n",
    "        self.classifier, self.label_encoder, metadata = model_manager.load_model(model_path)\n",
    "        \n",
    "        # Load embedding model\n",
    "        embedding_model_name = metadata['config']['embedding_model']\n",
    "        self.embedding_model = SentenceTransformer(embedding_model_name)\n",
    "        \n",
    "        if device.type == 'cuda':\n",
    "            self.embedding_model = self.embedding_model.to(device)\n",
    "    \n",
    "    def predict(self, plot_description: str, return_probabilities: bool = True, \n",
    "               top_n: int = 3) -> Dict:\n",
    "        \"\"\"Predict movie genre with confidence scores\"\"\"\n",
    "        try:\n",
    "            # Validate input\n",
    "            if not plot_description or len(plot_description.strip()) < 10:\n",
    "                raise ValueError(\"Plot description too short (minimum 10 characters)\")\n",
    "            \n",
    "            # Generate embedding\n",
    "            plot_embedding = self.embedding_model.encode(\n",
    "                [plot_description], \n",
    "                device=device.type,\n",
    "                normalize_embeddings=True\n",
    "            )\n",
    "            \n",
    "            # Get prediction\n",
    "            prediction = self.classifier.predict(plot_embedding)[0]\n",
    "            predicted_genre = self.label_encoder.classes_[prediction]\n",
    "            \n",
    "            result = {\n",
    "                'predicted_genre': predicted_genre,\n",
    "                'plot': plot_description[:100] + '...' if len(plot_description) > 100 else plot_description\n",
    "            }\n",
    "            \n",
    "            if return_probabilities:\n",
    "                probabilities = self.classifier.predict_proba(plot_embedding)[0]\n",
    "                top_indices = np.argsort(probabilities)[::-1][:top_n]\n",
    "                \n",
    "                result['confidence_scores'] = []\n",
    "                for idx in top_indices:\n",
    "                    genre = self.label_encoder.classes_[idx]\n",
    "                    confidence = probabilities[idx]\n",
    "                    result['confidence_scores'].append({\n",
    "                        'genre': genre,\n",
    "                        'confidence': float(confidence)\n",
    "                    })\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Prediction failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def predict_batch(self, plot_descriptions: List[str]) -> List[Dict]:\n",
    "        \"\"\"Batch prediction for multiple plots\"\"\"\n",
    "        return [self.predict(plot) for plot in plot_descriptions]\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = MovieGenrePredictor()\n",
    "print(\"âœ… Production predictor ready!\")\n",
    "\n",
    "# Quick test with one example\n",
    "test_plot = \"A young wizard discovers his magical heritage and attends a school for magic\"\n",
    "result = predictor.predict(test_plot, top_n=3)\n",
    "\n",
    "print(f\"\\nğŸ¬ Quick Test:\")\n",
    "print(f\"Plot: {result['plot']}\")\n",
    "print(f\"ğŸ¯ Predicted: {result['predicted_genre']} ({result['confidence_scores'][0]['confidence']:.1%})\")\n",
    "\n",
    "print(f\"\\nâœ… Predictor working! Use interactive_movie_testing() for more tests.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ® Interactive Testing Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_movie_testing():\n",
    "    \"\"\"Interactive testing interface\"\"\"\n",
    "    # Check if all required variables are available\n",
    "    required_vars = ['trainer', 'embedding_gen', 'X_test', 'y_test', 'X_train', 'evaluation_results']\n",
    "    missing_vars = [var for var in required_vars if var not in globals()]\n",
    "    \n",
    "    if missing_vars:\n",
    "        print(f\"âŒ Error: Missing required variables: {', '.join(missing_vars)}\")\n",
    "        print(\"ğŸ’¡ Please run all previous cells first to train the model!\")\n",
    "        print(\"ğŸ”„ Make sure you've completed the training pipeline before testing.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nğŸ® INTERACTIVE MOVIE GENRE PREDICTION\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ğŸ¬ Enter movie plots to see AI predictions!\")\n",
    "    print(\"ğŸ’¡ Type 'quit' to exit, 'stats' for model performance\")\n",
    "    print()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            plot = input(\"ğŸ¬ Enter movie plot (or 'quit'/'stats'): \").strip()\n",
    "            \n",
    "            if plot.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"ğŸ‘‹ Thanks for testing!\")\n",
    "                break\n",
    "            \n",
    "            if plot.lower() == 'stats':\n",
    "                print(f\"\\nğŸ“Š MODEL PERFORMANCE:\")\n",
    "                print(f\"   ğŸ¯ Test Accuracy: {evaluation_results['metrics']['accuracy']:.1%}\")\n",
    "                print(f\"   ğŸ“ˆ Precision: {evaluation_results['metrics']['precision']:.3f}\")\n",
    "                print(f\"   ğŸ“‰ Recall: {evaluation_results['metrics']['recall']:.3f}\")\n",
    "                print(f\"   ğŸª F1-Score: {evaluation_results['metrics']['f1_score']:.3f}\")\n",
    "                print(f\"   ğŸ­ Genres: {len(trainer.label_encoder.classes_)}\")\n",
    "                print(f\"   ğŸ“š Training samples: {len(X_train)}\")\n",
    "                print(f\"   ğŸ§ª Test samples: {len(X_test)}\")\n",
    "                continue\n",
    "            \n",
    "            if len(plot) < 10:\n",
    "                print(\"âš ï¸ Please enter a longer plot (at least 10 characters)\")\n",
    "                continue\n",
    "            \n",
    "            # Make prediction\n",
    "            result = predictor.predict(plot, top_n=5)\n",
    "            \n",
    "            print(f\"\\nğŸ¤– AI Analysis:\")\n",
    "            print(f\"ğŸ¯ Predicted Genre: {result['predicted_genre']}\")\n",
    "            print(f\"ğŸ“Š Confidence Breakdown:\")\n",
    "            \n",
    "            for i, score in enumerate(result['confidence_scores']):\n",
    "                emoji = \"ğŸ¥‡\" if i == 0 else \"ğŸ¥ˆ\" if i == 1 else \"ğŸ¥‰\" if i == 2 else f\"{i+1}.\"\n",
    "                bar_length = int(score['confidence'] * 20)\n",
    "                bar = \"â–ˆ\" * bar_length + \"â–‘\" * (20 - bar_length)\n",
    "                print(f\"   {emoji} {score['genre']:<15} {bar} {score['confidence']:.3f} ({score['confidence']*100:.1f}%)\")\n",
    "            \n",
    "            print()\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nğŸ‘‹ Session interrupted. Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "            print(\"ğŸ’¡ Please try again with a different plot.\")\n",
    "\n",
    "# âš ï¸ IMPORTANT: Uncomment the line below to start interactive testing\n",
    "# NOTE: Make sure you've run all previous cells first!\n",
    "# interactive_movie_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ğŸš€ Deployment Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check deployment dependencies (already installed in Cell 2)\n",
    "deployment_packages = ['skl2onnx', 'onnx', 'onnxruntime']\n",
    "\n",
    "all_available = True\n",
    "for package in deployment_packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        all_available = False\n",
    "        break\n",
    "\n",
    "if all_available:\n",
    "    print(\"âœ… All deployment dependencies available!\")\n",
    "else:\n",
    "    print(\"âš ï¸ Some deployment dependencies missing. Run Cell 2 to install all packages.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert trained model to ONNX format for deployment\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "def convert_model_to_onnx(classifier, output_path=\"movie_genre_classifier.onnx\"):\n",
    "    \"\"\"Convert sklearn model to ONNX format for deployment\"\"\"\n",
    "    try:\n",
    "        initial_type = [('float_input', FloatTensorType([None, 768]))]\n",
    "        onnx_model = convert_sklearn(classifier, initial_types=initial_type)\n",
    "        \n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(onnx_model.SerializeToString())\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ONNX conversion failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Convert the best classifier to ONNX\n",
    "if 'trainer' in globals() and trainer.best_model is not None:\n",
    "    onnx_path = convert_model_to_onnx(trainer.best_model)\n",
    "    print(f\"âœ… ONNX model saved: {onnx_path}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No trained model found. Run the training pipeline first!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ğŸ¯ Next Steps: Production Deployment\n",
    "\n",
    "### **ğŸ­ For OpenShift AI Model Serving:**\n",
    "1. **Upload ONNX model** to MinIO or S3 storage\n",
    "2. **Create InferenceService** with multi-model serving platform  \n",
    "3. **Deploy Flask web app** for user interface\n",
    "4. **Set up monitoring** and model management\n",
    "\n",
    "### **ğŸ“š Deployment Resources:**\n",
    "- **Complete Guide**: See `openshift_ai_movie_blog.txt` for full deployment walkthrough\n",
    "- **MinIO Setup**: S3-compatible storage configuration\n",
    "- **Model Serving**: ONNX model deployment on OpenShift AI\n",
    "- **Web App**: Containerized Flask application with UI\n",
    "\n",
    "### **ğŸ› ï¸ Alternative Deployments:**\n",
    "- **Local API**: Use `predictor.predict()` in Flask/FastAPI\n",
    "- **Batch Processing**: Use `predictor.predict_batch()` for bulk predictions  \n",
    "- **Cloud Platforms**: Deploy to AWS SageMaker, Azure ML, or GCP AI Platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ‰ IMPROVED MPNET MOVIE CLASSIFIER - COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ† Final Performance:\")\n",
    "print(f\"   â€¢ Test Accuracy: {evaluation_results['metrics']['accuracy']:.1%}\")\n",
    "print(f\"   â€¢ Precision: {evaluation_results['metrics']['precision']:.3f}\")\n",
    "print(f\"   â€¢ Recall: {evaluation_results['metrics']['recall']:.3f}\")\n",
    "print(f\"   â€¢ F1-Score: {evaluation_results['metrics']['f1_score']:.3f}\")\n",
    "print(f\"\\nğŸ”§ Technical Improvements:\")\n",
    "print(f\"   âœ… Security: Replaced eval() with json.loads()\")\n",
    "print(f\"   âœ… Modularity: Separated into classes and modules\")\n",
    "print(f\"   âœ… Error Handling: Comprehensive validation\")\n",
    "print(f\"   âœ… Model Persistence: Save/load functionality\")\n",
    "print(f\"   âœ… Configuration: YAML-based config management\")\n",
    "print(f\"   âœ… Cross-Validation: {config.training.cv_folds}-fold CV with hyperparameter tuning\")\n",
    "print(f\"   âœ… Logging: Structured logging system\")\n",
    "print(f\"   âœ… Performance: Optimized embeddings with caching\")\n",
    "print(f\"\\nğŸ’¾ Model saved to: {model_path}\")\n",
    "print(f\"\\nğŸš€ Ready for Production:\")\n",
    "print(f\"   â€¢ Call predictor.predict('your plot') for single predictions\")\n",
    "print(f\"   â€¢ Call predictor.predict_batch([plots]) for batch predictions\")\n",
    "print(f\"   â€¢ Call interactive_movie_testing() for interactive mode\")\n",
    "print(f\"   â€¢ Model can be loaded with MovieGenrePredictor(model_path)\")\n",
    "print(f\"\\nğŸ“ˆ Next Steps:\")\n",
    "print(f\"   â€¢ Run deployment preparation cells (Cell 29-30) for ONNX conversion\")\n",
    "print(f\"   â€¢ Follow openshift_ai_movie_blog.txt for OpenShift AI deployment\")  \n",
    "print(f\"   â€¢ Deploy as REST API with Flask/FastAPI\")\n",
    "print(f\"   â€¢ Add A/B testing framework\")\n",
    "print(f\"   â€¢ Implement model monitoring\")\n",
    "print(f\"   â€¢ Add data drift detection\")\n",
    "print(f\"   â€¢ Create automated retraining pipeline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
